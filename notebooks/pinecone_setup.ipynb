{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración y Conexión a Pinecone\n",
    "\n",
    "En este bloque de código, se establece la conexión con el servicio de Pinecone, una plataforma de vector search que permite gestionar y consultar índices de manera eficiente. Este proceso es esencial para almacenar y recuperar información de manera óptima, especialmente al trabajar con datos de alta dimensionalidad, como embeddings de texto o imágenes. A continuación, se describen las operaciones realizadas:\n",
    "\n",
    "1. **Importación de Librerías**:\n",
    "   - Se importan las bibliotecas necesarias: \n",
    "     - `os` para manejar variables de entorno y la configuración del sistema.\n",
    "     - `Pinecone` y `ServerlessSpec` para interactuar con la API de Pinecone.\n",
    "     - `dotenv` para cargar las variables de entorno desde un archivo `.env`.\n",
    "\n",
    "2. **Carga de Variables de Entorno**:\n",
    "   - La función `load_dotenv()` se utiliza para cargar las variables de entorno definidas en un archivo `.env`, permitiendo acceder a credenciales sensibles, como la clave API de Pinecone.\n",
    "\n",
    "3. **Creación de una Instancia de Pinecone**:\n",
    "   - Se obtiene la clave API utilizando `os.getenv(\"key\")`, que permite autenticar la conexión con el servicio de Pinecone.\n",
    "   - Se crea una instancia de `Pinecone` usando la clave API, estableciendo una conexión que permitirá realizar operaciones en la plataforma.\n",
    "\n",
    "4. **Creación del Índice**:\n",
    "   - Se verifica si ya existe un índice llamado **'series'** utilizando `pc.list_indexes().names()`. Si no existe, se procede a crearlo.\n",
    "   - La creación del índice se realiza con las siguientes especificaciones:\n",
    "     - **Nombre del Índice**: 'series'\n",
    "     - **Dimensión**: 384, que representa la dimensionalidad de los vectores que se almacenarán en el índice.\n",
    "     - **Métrica**: `euclidean`, que se utilizará para calcular la distancia entre los vectores.\n",
    "     - **Especificaciones del Servidor**: Se elige la opción de **Serverless** en la nube de AWS, con la región establecida en **us-east-1**. Esto proporciona flexibilidad y escalabilidad en el manejo de los datos.\n",
    "\n",
    "5. **Conexión al Índice**:\n",
    "   - Finalmente, se conecta al índice **'series'** creando una instancia de `index` que permitirá realizar operaciones de inserción y consulta sobre los datos almacenados.\n",
    "\n",
    "Este proceso de configuración es crucial para preparar el entorno de trabajo y garantizar que se pueda interactuar con Pinecone de manera eficiente, permitiendo el almacenamiento y búsqueda de embeddings de manera escalable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Crea una instancia de Pinecone\n",
    "API_key = os.getenv(\"key\")\n",
    "pc = Pinecone(api_key = API_key)\n",
    "# Crear un índice llamado 'books'\n",
    "if 'series' not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name='series',\n",
    "        dimension=384,  \n",
    "        metric='euclidean',  \n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',  \n",
    "            region='us-east-1'  \n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Conectar al índice\n",
    "index = pc.Index('series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión del embedding: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar el modelo\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Ejemplo con un modelo\n",
    "\n",
    "# Generar embeddings para algunas muestras de texto\n",
    "embeddings = model.encode([\"Ejemplo de texto para verificar la dimensión\"])\n",
    "\n",
    "# Imprimir la forma del array de embeddings\n",
    "print(f\"Dimensión del embedding: {embeddings.shape[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_finalp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
